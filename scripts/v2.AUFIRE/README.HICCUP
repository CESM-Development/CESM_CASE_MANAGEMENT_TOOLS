What I've done:

git clone https://github.com/E3SM-Project/HICCUP ./HICCUP

bash
source /global/common/software/e3sm/anaconda_envs/load_latest_e3sm_unified_pm-cpu.sh


From README.MD
conda create --name hiccup_env -c conda-forge xarray dask pandas numpy scipy netcdf4 pynio hdf5 cdsapi tempest-remap nco


=======================================
From Walter Hannah:  August 21, 2023
The first step is to grab the HICCUP package from here => https://github.com/E3SM-Project/HICCUP
After cloning that you need to follow the set up instructions to create a new conda env and run “./setup.py install”

Afterwards you can extract the scripts in the attached zip archive, which contains these files:

2023-CATALYST.batch.py
2023-CATALYST.batch.sh
2023-CATALYST.create_IC_from_obs.py
get_hindcast_data.ERA5.py

get_hindcast_data.ERA5.py is for aquiring the ERA5 data that will be turned into the initial condition (IC) files. Each IC needs both vertically resolved and surface data, which end up coming in separate files.
2023-CATALYST.create_IC_from_obs.py is where all the action happens, but for various reasons it can only process/create a single IC file at a time, so…
I created 2023-CATALYST.batch.py to loop through all the hindcast dates and call the previous script.
However, You might not want to run this on a login node, so if that’s the case then you can use 2023-CATALYST.batch.sh to run it as a batch job.
Make sure you go through all the scripts and adjust the various paths before calling them. You’ll also likely need to adjust the batch job parameters to change the project account and whatnot.
Feel free to hit me with any questions.
